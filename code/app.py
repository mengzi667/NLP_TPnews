import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F
import pandas as pd
import plotly.express as px
import os

# --- 1. é¡µé¢é…ç½® (Page Configuration) ---
# st.set_page_config() å¿…é¡»æ˜¯è„šæœ¬ä¸­ç¬¬ä¸€ä¸ªè¢«è°ƒç”¨çš„Streamlitå‘½ä»¤
st.set_page_config(
    page_title="åŸå¸‚äº¤é€šèˆ†æƒ…æ„å›¾è¯†åˆ«ç³»ç»Ÿ",
    page_icon="ğŸš‡",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- 2. åŠ è½½æ¨¡å‹ (Model Loading) ---
# ä½¿ç”¨ @st.cache_resource è£…é¥°å™¨æ¥ç¼“å­˜æ¨¡å‹ï¼Œé¿å…æ¯æ¬¡åˆ·æ–°é¡µé¢éƒ½é‡æ–°åŠ è½½
# è¿™ä¼šæå¤§åœ°æå‡åº”ç”¨çš„å“åº”é€Ÿåº¦
@st.cache_resource
def load_model():
    """
    åŠ è½½æœ¬åœ°è®­ç»ƒå¥½çš„æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚
    è¿™ä¸ªå‡½æ•°åªä¼šåœ¨ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶æ‰§è¡Œï¼Œä¹‹åçš„ç»“æœä¼šè¢«ç¼“å­˜ã€‚
    """
    # TODO: (éå¸¸é‡è¦!) å°†è¿™é‡Œçš„è·¯å¾„æ›¿æ¢ä¸ºä½ æœ€ç»ˆçš„ã€æ€§èƒ½æœ€å¥½çš„é‚£ä¸ªæ¨¡å‹checkpointçš„è·¯å¾„
    # ä¾‹å¦‚: "./model_results_weighted/checkpoint-1611"
    model_path = "./models/mac_hyper_search_results/run-11/checkpoint-716" 

    try:
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            st.error(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡å‹è·¯å¾„ '{model_path}'ã€‚è¯·ç¡®è®¤è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
            return None, None
            
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)
        print("æ¨¡å‹å’Œåˆ†è¯å™¨åŠ è½½æˆåŠŸï¼")
        return tokenizer, model
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦ä¸ºæœ‰æ•ˆçš„Hugging Faceæ¨¡å‹ç›®å½•ã€‚")
        st.error(f"é”™è¯¯è¯¦æƒ…: {e}")
        return None, None

# æ‰§è¡ŒåŠ è½½
tokenizer, model = load_model()

# --- 3. é¡µé¢æ ‡é¢˜å’Œç®€ä»‹ (Title and Introduction) ---
st.title("ğŸš‡ åŸå¸‚äº¤é€šèˆ†æƒ…æ„å›¾è¯†åˆ«ç³»ç»Ÿ")
st.markdown("""
æ¬¢è¿ä½¿ç”¨æœ¬ç³»ç»Ÿï¼è¿™æ˜¯ä¸€ä¸ªåŸºäº `MacBERT` å¾®è°ƒæ¨¡å‹çš„è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«å…³äº**åŸå¸‚äº¤é€š**ï¼ˆåœ°é“ã€å…¬äº¤ã€å‡ºç§Ÿè½¦ç­‰ï¼‰çš„æ–‡æœ¬æ‰€è¡¨è¾¾çš„æ ¸å¿ƒæ„å›¾ã€‚
æ‚¨å¯ä»¥åœ¨ä¸‹æ–¹çš„æ–‡æœ¬æ¡†ä¸­è¾“å…¥ä»»ä½•åé¦ˆã€é—®é¢˜æˆ–å»ºè®®ï¼Œæ¨¡å‹å°†ä¼šç»™å‡ºå®ƒçš„åˆ¤æ–­ã€‚
""")
st.markdown("---")


# --- 4. ä¸»åº”ç”¨ç•Œé¢ (Main Interface) ---
if model is None:
    st.warning("æ¨¡å‹æœªèƒ½æˆåŠŸåŠ è½½ï¼Œåº”ç”¨æ— æ³•æ­£å¸¸å·¥ä½œã€‚è¯·æ£€æŸ¥ç»ˆç«¯ä¸­çš„é”™è¯¯ä¿¡æ¯ã€‚")
else:
    col1, col2 = st.columns([2, 1]) # åˆ›å»ºä¸¤åˆ—ï¼Œå·¦è¾¹æ›´å®½

    with col1:
        st.header("âœï¸ è¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬:")
        # ä½¿ç”¨è¡¨å•æ¥ç»„ç»‡è¾“å…¥å’ŒæŒ‰é’®ï¼Œå¯ä»¥é˜²æ­¢æ¯æ¬¡è¾“å…¥éƒ½é‡æ–°è¿è¡Œæ•´ä¸ªé¡µé¢
        with st.form("intent_form"):
            text_input = st.text_area(
                "è¾“å…¥æ–‡æœ¬:", 
                "å¼ºçƒˆå»ºè®®åœ°é“11å·çº¿åœ¨æ—©é«˜å³°å¢åŠ å‡ ç­è½¦ï¼Œç°åœ¨ç­‰ä¸€è¶Ÿçš„æ—¶é—´ä¹Ÿå¤ªé•¿äº†ï¼", 
                height=200,
                placeholder="ä¾‹å¦‚ï¼šä¸Šæµ·åœ°é“çš„ç©ºè°ƒæ˜¯æ‰“ç®—æŠŠäººå†»æ­»å—ï¼Ÿ"
            )
            submitted = st.form_submit_button("ğŸš€ å¼€å§‹åˆ†æ")

    with col2:
        st.header("ğŸ’¡ æ„å›¾ç±»åˆ«è¯´æ˜")
        st.info("""
        - **å’¨è¯¢:** è¯¢é—®ä¿¡æ¯ã€æµç¨‹ç­‰ã€‚
        - **æ±‚åŠ©:** è¯·æ±‚å…·ä½“å¸®åŠ©ï¼ˆå¦‚å¯»ç‰©ï¼‰ã€‚
        - **æŠ•è¯‰:** è¡¨è¾¾å¼ºçƒˆä¸æ»¡ã€‚
        - **ä¸¾æŠ¥:** æ­å‘è¿è§„æˆ–å®‰å…¨éšæ‚£ã€‚
        - **å»ºè®®:** æå‡ºå…·ä½“æ”¹è¿›æ–¹æ¡ˆã€‚
        - **æ­£é¢åé¦ˆ:** æ˜ç¡®çš„èµæ‰¬æˆ–æ„Ÿè°¢ã€‚
        """)

    # --- 5. æ¨¡å‹æ¨ç†ä¸ç»“æœå±•ç¤º (Inference and Display) ---
    if submitted:
        if not text_input.strip():
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡æœ¬å†…å®¹åå†è¿›è¡Œåˆ†æã€‚")
        else:
            with st.spinner('æ¨¡å‹æ­£åœ¨å…¨åŠ›åˆ†æä¸­ï¼Œè¯·ç¨å€™...'):
                # a. é¢„å¤„ç†è¾“å…¥
                inputs = tokenizer(text_input, return_tensors="pt", truncation=True, padding=True, max_length=256)
                
                # b. æ¨¡å‹æ¨ç†
                with torch.no_grad(): # åœ¨æ¨ç†æ¨¡å¼ä¸‹ï¼Œä¸è®¡ç®—æ¢¯åº¦ä»¥åŠ é€Ÿ
                    outputs = model(**inputs)
                
                # c. åå¤„ç†ç»“æœ
                logits = outputs.logits
                probabilities = F.softmax(logits, dim=-1).flatten().tolist()
                
                # è·å–æ ‡ç­¾åç§°å’Œå¯¹åº”çš„æ¦‚ç‡
                labels = list(model.config.id2label.values())
                prob_df = pd.DataFrame({
                    'æ„å›¾ç±»åˆ«': labels,
                    'æ¦‚ç‡': probabilities
                }).sort_values(by='æ¦‚ç‡', ascending=False).reset_index(drop=True)

                # d. å±•ç¤ºç»“æœ
                st.markdown("---")
                st.header("ğŸ“ˆ åˆ†æç»“æœ")
                
                # åˆ†ä¸¤åˆ—å±•ç¤º
                res_col1, res_col2 = st.columns(2)
                
                with res_col1:
                    # ä½¿ç”¨st.metricå±•ç¤ºæœ€å¯èƒ½çš„ç±»åˆ«
                    st.metric(
                        label="**æœ€é«˜æ¦‚ç‡æ„å›¾**", 
                        value=prob_df.iloc[0]['æ„å›¾ç±»åˆ«'],
                        help=f"æ¨¡å‹è®¤ä¸ºè¿™æ¡æ–‡æœ¬æœ€æœ‰å¯èƒ½å±äºè¿™ä¸ªç±»åˆ«ï¼Œç½®ä¿¡åº¦ä¸º {prob_df.iloc[0]['æ¦‚ç‡']:.2%}"
                    )
                    st.write("è¯¦ç»†æ¦‚ç‡åˆ†å¸ƒï¼š")
                    # ä½¿ç”¨st.dataframeå±•ç¤ºå¸¦è¿›åº¦æ¡çš„è¡¨æ ¼
                    st.dataframe(prob_df,
                                  use_container_width=True,
                                  column_config={
                                      "æ¦‚ç‡": st.column_config.ProgressColumn(
                                          "æ¦‚ç‡",
                                          format="%.2f%%",
                                          min_value=0,
                                          max_value=1,
                                      ),
                                  },
                                  hide_index=True)

                with res_col2:
                    # ä½¿ç”¨Plotlyç»˜åˆ¶æ¼‚äº®çš„æ¡å½¢å›¾
                    fig = px.bar(
                        prob_df, 
                        x='æ¦‚ç‡', 
                        y='æ„å›¾ç±»åˆ«', 
                        orientation='h', 
                        title='å„æ„å›¾ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒå›¾',
                        text_auto='.2%',
                        color_discrete_sequence=px.colors.sequential.Blues_r
                    )
                    fig.update_layout(
                        yaxis={'categoryorder':'total ascending'},
                        xaxis_title="æ¦‚ç‡",
                        yaxis_title="æ„å›¾ç±»åˆ«"
                    )
                    st.plotly_chart(fig, use_container_width=True)

# --- 6. ä¾§è¾¹æ  (Sidebar) ---
st.sidebar.header("å…³äºæœ¬é¡¹ç›®")
st.sidebar.info(
    """
    è¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„NLPé¡¹ç›®ï¼Œæ—¨åœ¨é€šè¿‡AIæŠ€æœ¯èµ‹èƒ½åŸå¸‚äº¤é€šç®¡ç†ï¼Œè‡ªåŠ¨åˆ†ææµ·é‡ç¤¾æƒ…æ°‘æ„ï¼Œæå‡å“åº”æ•ˆç‡ã€‚
    
    **æ ¸å¿ƒæŠ€æœ¯æ ˆ:**
    - **æ•°æ®å·¥ç¨‹:** `requests`, `BeautifulSoup`, `pandas`
    - **æ™ºèƒ½æ ‡æ³¨:** LLM API (`é€šä¹‰åƒé—®`), `Prompt Engineering`
    - **æ¨¡å‹è®­ç»ƒ:** `PyTorch`, `Hugging Face Transformers`
    - **åŸºåº§æ¨¡å‹:** `hfl/chinese-macbert-base`
    - **åº”ç”¨æ„å»º:** `Streamlit`, `Plotly`
    """
)
st.sidebar.markdown("---")
st.sidebar.write("**å¼€å‘è€…:** æ½˜ç¦¹èŒ ç§¦èµ«")
st.sidebar.write("**GitHub:** https://github.com/mengzi667/NLP_TPnews.git")